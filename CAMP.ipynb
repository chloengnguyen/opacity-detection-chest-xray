{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keract-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keract import display_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'sample-xray.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for deep learning with Keras\n",
    "# Dr. Tirthajyoti Sarkar, Fremont, CA 94536\n",
    "# ==============================================\n",
    "\n",
    "# NOTES\n",
    "# Used tf.keras in general except in special functions where older/independent Keras has been used.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "  User can pass on the desired accuracy threshold while creating an instance of the class\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, acc_threshold=0.9, print_msg=True):\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.print_msg = print_msg\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get(\"acc\") > self.acc_threshold:\n",
    "            if self.print_msg:\n",
    "                print(\n",
    "                    \"\\nReached {}% accuracy so cancelling the training!\".format(\n",
    "                        self.acc_threshold\n",
    "                    )\n",
    "                )\n",
    "            self.model.stop_training = True\n",
    "        else:\n",
    "            if self.print_msg:\n",
    "                print(\"\\nAccuracy not high enough. Starting another epoch...\\n\")\n",
    "\n",
    "    def build_classification_model(\n",
    "        num_layers=1,\n",
    "        architecture=[32],\n",
    "        act_func=\"relu\",\n",
    "        input_shape=(28, 28),\n",
    "        output_class=10,\n",
    "    ):\n",
    "        \"\"\"\n",
    "  Builds a densely connected neural network model from user input\n",
    "  \n",
    "  Arguments\n",
    "          num_layers: Number of hidden layers\n",
    "          architecture: Architecture of the hidden layers (densely connected)\n",
    "          act_func: Activation function. Could be 'relu', 'sigmoid', or 'tanh'.\n",
    "          input_shape: Dimension of the input vector\n",
    "          output_class: Number of classes in the output vector\n",
    "  Returns\n",
    "          A neural net (Keras) model for classification\n",
    "  \"\"\"\n",
    "        layers = [tf.keras.layers.Flatten(input_shape=input_shape)]\n",
    "        if act_func == \"relu\":\n",
    "            activation = tf.nn.relu\n",
    "        elif act_func == \"sigmoid\":\n",
    "            activation = tf.nn.sigmoid\n",
    "        elif act_func == \"tanh\":\n",
    "            activation = tf.nn.tanh\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            layers.append(tf.keras.layers.Dense(architecture[i], activation=tf.nn.relu))\n",
    "        layers.append(tf.keras.layers.Dense(output_class, activation=tf.nn.softmax))\n",
    "\n",
    "        model = tf.keras.models.Sequential(layers)\n",
    "        return model\n",
    "\n",
    "\n",
    "def build_regression_model(\n",
    "    input_neurons=10, input_dim=1, num_layers=1, architecture=[32], act_func=\"relu\"\n",
    "):\n",
    "    \"\"\"\n",
    "  Builds a densely connected neural network model from user input\n",
    "  \n",
    "  Arguments\n",
    "          num_layers: Number of hidden layers\n",
    "          architecture: Architecture of the hidden layers (densely connected)\n",
    "          act_func: Activation function. Could be 'relu', 'sigmoid', or 'tanh'.\n",
    "          input_shape: Dimension of the input vector\n",
    "  Returns\n",
    "          A neural net (Keras) model for regression\n",
    "  \"\"\"\n",
    "    if act_func == \"relu\":\n",
    "        activation = tf.nn.relu\n",
    "    elif act_func == \"sigmoid\":\n",
    "        activation = tf.nn.sigmoid\n",
    "    elif act_func == \"tanh\":\n",
    "        activation = tf.nn.tanh\n",
    "\n",
    "    layers = [\n",
    "        tf.keras.layers.Dense(input_neurons, input_dim=input_dim, activation=activation)\n",
    "    ]\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        layers.append(tf.keras.layers.Dense(architecture[i], activation=activation))\n",
    "    layers.append(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model = tf.keras.models.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_train_classification_model(\n",
    "    model,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    callbacks=None,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1,\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "):\n",
    "    \"\"\"\n",
    "  Compiles and trains a given Keras model with the given data. \n",
    "  Assumes Adam optimizer for this implementation.\n",
    "  Assumes categorical cross-entropy loss.\n",
    "  \n",
    "  Arguments\n",
    "          learning_rate: Learning rate for the optimizer Adam\n",
    "          batch_size: Batch size for the mini-batch optimization\n",
    "          epochs: Number of epochs to train\n",
    "          verbose: Verbosity of the training process\n",
    "  \n",
    "  Returns\n",
    "  A copy of the model\n",
    "  \"\"\"\n",
    "\n",
    "    model_copy = model\n",
    "    model_copy.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    if callbacks != None:\n",
    "        model_copy.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[callbacks],\n",
    "            verbose=verbose,\n",
    "        )\n",
    "    else:\n",
    "        model_copy.fit(\n",
    "            x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose\n",
    "        )\n",
    "    return model_copy\n",
    "\n",
    "\n",
    "def compile_train_regression_model(\n",
    "    model,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    callbacks=None,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1,\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "):\n",
    "    \"\"\"\n",
    "  Compiles and trains a given Keras model with the given data for regression. \n",
    "  Assumes Adam optimizer for this implementation.\n",
    "  Assumes mean-squared-error loss\n",
    "  \n",
    "  Arguments\n",
    "          learning_rate: Learning rate for the optimizer Adam\n",
    "          batch_size: Batch size for the mini-batch operation\n",
    "          epochs: Number of epochs to train\n",
    "          verbose: Verbosity of the training process\n",
    "  \n",
    "  Returns\n",
    "  A copy of the model\n",
    "  \"\"\"\n",
    "\n",
    "    model_copy = model\n",
    "    model_copy.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    if callbacks != None:\n",
    "        model_copy.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[callbacks],\n",
    "            verbose=verbose,\n",
    "        )\n",
    "    else:\n",
    "        model_copy.fit(\n",
    "            x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose\n",
    "        )\n",
    "    return model_copy\n",
    "\n",
    "\n",
    "def plot_loss_acc(model, target_acc=0.9, title=None):\n",
    "    \"\"\"\n",
    "  Takes a Keras model and plots the loss and accuracy over epochs.\n",
    "  The same plot shows loss and accuracy on two axes - left and right (with separate scales)\n",
    "  Users can supply a title if desired\n",
    "  Arguments:\n",
    "            target_acc (optional): The desired/ target acc for the function to show a horizontal bar.\n",
    "            title (optional): A Python string object to show as the plot's title\n",
    "  \"\"\"\n",
    "    e = (\n",
    "        np.array(model.history.epoch) + 1\n",
    "    )  # Add one to the list of epochs which is zero-indexed\n",
    "    # Check to see if loss metric is in the model history\n",
    "    assert (\n",
    "        \"loss\" in model.history.history.keys()\n",
    "    ), \"No loss metric found in the model history\"\n",
    "    l = np.array(model.history.history[\"loss\"])\n",
    "    # Check to see if loss metric is in the model history\n",
    "    assert (\n",
    "        \"acc\" in model.history.history.keys()\n",
    "    ), \"No accuracy metric found in the model history\"\n",
    "    a = np.array(model.history.history[\"acc\"])\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = \"tab:red\"\n",
    "    ax1.set_xlabel(\"Epochs\", fontsize=15)\n",
    "    ax1.set_ylabel(\"Loss\", color=color, fontsize=15)\n",
    "    ax1.plot(e, l, color=color, lw=2)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = \"tab:blue\"\n",
    "    ax2.set_ylabel(\n",
    "        \"Accuracy\", color=color, fontsize=15\n",
    "    )  # we already handled the x-label with ax1\n",
    "    ax2.plot(e, a, color=color, lw=2)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    if title != None:\n",
    "        plt.title(title)\n",
    "    plt.hlines(\n",
    "        y=target_acc, xmin=1, xmax=e.max(), colors=\"k\", linestyles=\"dashed\", lw=3\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_train_val_acc(model, target_acc=0.9, title=None):\n",
    "    \"\"\"\n",
    "  Takes a Keras model and plots the training and validation set accuracy over epochs.\n",
    "  The same plot shows both the accuracies on two axes - left and right (with separate scales)\n",
    "  Users can supply a title if desired\n",
    "  Arguments:\n",
    "            target_acc (optional): The desired/ target acc for the function to show a horizontal bar.\n",
    "            title (optional): A Python string object to show as the plot's title\n",
    "  \"\"\"\n",
    "    e = (\n",
    "        np.array(model.history.epoch) + 1\n",
    "    )  # Add one to the list of epochs which is zero-indexed\n",
    "    # Check to see if loss metric is in the model history\n",
    "    assert (\n",
    "        \"acc\" in model.history.history.keys()\n",
    "    ), \"No accuracy metric found in the model history\"\n",
    "    a = np.array(model.history.history[\"acc\"])\n",
    "    # Check to see if loss metric is in the model history\n",
    "    assert (\n",
    "        \"val_acc\" in model.history.history.keys()\n",
    "    ), \"No validation accuracy metric found in the model history\"\n",
    "    va = np.array(model.history.history[\"val_acc\"])\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = \"tab:red\"\n",
    "    ax1.set_xlabel(\"Epochs\", fontsize=15)\n",
    "    ax1.set_ylabel(\"Training accuracy\", color=color, fontsize=15)\n",
    "    ax1.plot(e, a, color=color, lw=2)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = \"tab:blue\"\n",
    "    ax2.set_ylabel(\n",
    "        \"Validation accuracy\", color=color, fontsize=15\n",
    "    )  # we already handled the x-label with ax1\n",
    "    ax2.plot(e, va, color=color, lw=2)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    if title != None:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.hlines(\n",
    "        y=target_acc, xmin=1, xmax=e.max(), colors=\"k\", linestyles=\"dashed\", lw=3\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_CNN(\n",
    "    train_directory,\n",
    "    target_size=(256, 256),\n",
    "    callbacks=None,\n",
    "    classes=None,\n",
    "    batch_size=128,\n",
    "    num_classes=2,\n",
    "    num_epochs=20,\n",
    "    verbose=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a conv net for a given dataset contained within a training directory.\n",
    "    Users can just supply the path of the training directory and get back a fully trained, 5-layer, convolutional network.\n",
    "    \n",
    "    Arguments:\n",
    "            train_directory: The directory where the training images are stored in separate folders.\n",
    "                            These folders should be named as per the classes.\n",
    "            target_size: Target size for the training images. A tuple e.g. (200,200)\n",
    "            classes: A Python list with the classes \n",
    "            batch_size: Batch size for training\n",
    "            num_epochs: Number of epochs for training\n",
    "            num_classes: Number of output classes to consider\n",
    "            verbose: Verbosity level of the training, passed on to the `fit_generator` method\n",
    "    Returns:\n",
    "            A trained conv net model\n",
    "    \n",
    "    \"\"\"\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "    # ImageDataGenerator object instance with scaling\n",
    "    train_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "    # Flow training images in batches using the generator\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_directory,  # This is the source directory for training images\n",
    "        target_size=target_size,  # All images will be resized to 200 x 200\n",
    "        batch_size=batch_size,\n",
    "        # Specify the classes explicitly\n",
    "        classes=classes,\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    input_shape = tuple(list(target_size) + [3])\n",
    "\n",
    "    # Model architecture\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
    "            # The first convolution\n",
    "            tf.keras.layers.Conv2D(\n",
    "                16, (3, 3), activation=\"relu\", input_shape=input_shape\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            # The second convolution\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            # The third convolution\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            # The fourth convolution\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            # The fifth convolution\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            # Flatten the results to feed into a dense layer\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # 512 neuron in the fully-connected layer\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            # Output neurons for `num_classes` classes with the softmax activation\n",
    "            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Optimizer and compilation\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=RMSprop(lr=0.001), metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    # Total sample count\n",
    "    total_sample = train_generator.n\n",
    "\n",
    "    # Training\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=int(total_sample / batch_size),\n",
    "        epochs=num_epochs,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_CNN_keras(\n",
    "    train_directory,\n",
    "    target_size=(256, 256),\n",
    "    classes=None,\n",
    "    batch_size=128,\n",
    "    num_classes=2,\n",
    "    num_epochs=20,\n",
    "    verbose=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a conv net for a given dataset contained within a training directory.\n",
    "    Users can just supply the path of the training directory and get back a fully trained, 5-layer, convolutional network.\n",
    "    \n",
    "    Arguments:\n",
    "            train_directory: The directory where the training images are stored in separate folders.\n",
    "                            These folders should be named as per the classes.\n",
    "            target_size: Target size for the training images. A tuple e.g. (200,200)\n",
    "            classes: A Python list with the classes \n",
    "            batch_size: Batch size for training\n",
    "            num_epochs: Number of epochs for training\n",
    "            num_classes: Number of output classes to consider\n",
    "            verbose: Verbosity level of the training, passed on to the `fit_generator` method\n",
    "    Returns:\n",
    "            A trained conv net model\n",
    "    \n",
    "    \"\"\"\n",
    "    from keras.layers import Conv2D, MaxPooling2D\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from keras.models import Sequential\n",
    "    from keras.optimizers import RMSprop\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    # ImageDataGenerator object instance with scaling\n",
    "    train_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "    # Flow training images in batches using the generator\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_directory,  # This is the source directory for training images\n",
    "        target_size=target_size,  # All images will be resized to 200 x 200\n",
    "        batch_size=batch_size,\n",
    "        # Specify the classes explicitly\n",
    "        classes=classes,\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    input_shape = tuple(list(target_size) + [3])\n",
    "\n",
    "    # Model architecture\n",
    "    model = Sequential(\n",
    "        [\n",
    "            # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
    "            # The first convolution\n",
    "            Conv2D(16, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "            MaxPooling2D(2, 2),\n",
    "            # The second convolution\n",
    "            Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D(2, 2),\n",
    "            # The third convolution\n",
    "            Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D(2, 2),\n",
    "            # The fourth convolution\n",
    "            Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D(2, 2),\n",
    "            # The fifth convolution\n",
    "            Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D(2, 2),\n",
    "            # Flatten the results to feed into a dense layer\n",
    "            Flatten(),\n",
    "            # 512 neuron in the fully-connected layer\n",
    "            Dense(512, activation=\"relu\"),\n",
    "            # Output neurons for `num_classes` classes with the softmax activation\n",
    "            Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Optimizer and compilation\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=RMSprop(lr=0.001), metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    # Total sample count\n",
    "    total_sample = train_generator.n\n",
    "\n",
    "    # Training\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=int(total_sample / batch_size),\n",
    "        epochs=num_epochs,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_image(img_path, model=None, rescale=255, resize=(256, 256)):\n",
    "    \"\"\"\n",
    "    Preprocesses a given image for prediction with a trained model, with rescaling and resizing options\n",
    "    \n",
    "    Arguments:\n",
    "            img_path: The path to the image file\n",
    "            rescale: A float or integer indicating required rescaling. \n",
    "                    The image array will be divided (scaled) by this number.\n",
    "            resize: A tuple indicating desired target size. \n",
    "                    This should match the input shape as expected by the model\n",
    "    Returns:\n",
    "            img: A processed image.\n",
    "    \"\"\"\n",
    "    from keras.preprocessing.image import img_to_array, load_img\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    assert type(img_path) == str, \"Image path must be a string\"\n",
    "    assert (\n",
    "        type(rescale) == int or type(rescale) == float\n",
    "    ), \"Rescale factor must be either a float or int\"\n",
    "    assert (\n",
    "        type(resize) == tuple and len(resize) == 2\n",
    "    ), \"Resize target must be a tuple with two elements\"\n",
    "\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    img = img / float(rescale)\n",
    "    img = cv2.resize(img, resize)\n",
    "    if model != None:\n",
    "        if len(model.input_shape) == 4:\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def pred_prob_with_model(img_path, model, rescale=255, resize=(256, 256)):\n",
    "    \"\"\"\n",
    "    Tests a given image with a trained model, with rescaling and resizing options\n",
    "    \n",
    "    Arguments:\n",
    "            img_path: The path to the image file\n",
    "            model: The trained Keras model\n",
    "            rescale: A float or integer indicating required rescaling. \n",
    "                    The image array will be divided (scaled) by this number.\n",
    "            resize: A tuple indicating desired target size. \n",
    "                    This should match the input shape as expected by the model\n",
    "    Returns:\n",
    "            pred: A prediction vector (Numpy array).\n",
    "                  Could be either classes or probabilities depending on the model.\n",
    "    \"\"\"\n",
    "    from keras.preprocessing.image import img_to_array, load_img\n",
    "    import cv2\n",
    "\n",
    "    assert type(img_path) == str, \"Image path must be a string\"\n",
    "    assert (\n",
    "        type(rescale) == int or type(rescale) == float\n",
    "    ), \"Rescale factor must be either a float or int\"\n",
    "    assert (\n",
    "        type(resize) == tuple and len(resize) == 2\n",
    "    ), \"Resize target must be a tuple with two elements\"\n",
    "\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    img = img / float(rescale)\n",
    "    img = cv2.resize(img, resize)\n",
    "    if len(model.input_shape) == 4:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    pred = model.predict(img)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def pred_class_with_model(img_path, model, rescale=255, resize=(256, 256)):\n",
    "    \"\"\"\n",
    "    Tests a given image with a trained model, with rescaling and resizing options\n",
    "    \n",
    "    Arguments:\n",
    "            img_path: The path to the image file\n",
    "            model: The trained Keras model\n",
    "            rescale: A float or integer indicating required rescaling. \n",
    "                    The image array will be divided (scaled) by this number.\n",
    "            resize: A tuple indicating desired target size. \n",
    "                    This should match the input shape as expected by the model\n",
    "    Returns:\n",
    "            pred: A prediction vector (Numpy array).\n",
    "                  Could be either classes or probabilities depending on the model.\n",
    "    \"\"\"\n",
    "    from keras.preprocessing.image import img_to_array, load_img\n",
    "    import cv2\n",
    "\n",
    "    assert type(img_path) == str, \"Image path must be a string\"\n",
    "    assert (\n",
    "        type(rescale) == int or type(rescale) == float\n",
    "    ), \"Rescale factor must be either a float or int\"\n",
    "    assert (\n",
    "        type(resize) == tuple and len(resize) == 2\n",
    "    ), \"Resize target must be a tuple with two elements\"\n",
    "\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    img = img / float(rescale)\n",
    "    img = cv2.resize(img, resize)\n",
    "    if len(model.input_shape) == 4:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    pred = model.predict(img)\n",
    "    pred_class = pred.argmax(axis=-1)\n",
    "\n",
    "    return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-847d1303ba63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDL_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_CNN_keras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
